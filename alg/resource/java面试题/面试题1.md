# Java基础

## JAVA volatile关键字以及线程安全;(2-1)   不同等级的深度,扩展;    
    1.Java的线程安全问题 （主内存，工作内存） 		   
      - Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。
	 由于java中的每个线程有自己的工作空间，这种工作空间相当于上面所说的高速缓存，因此多个线程在处理一个共享变量的时候，就会出现线程安全问题。

    2.volatile保证变量可见性的原理
      - volatile  在多线程环境下，某个共享变量如果被其中一个线程给修改了，其他线程能够立即知道这个共享变量已经被修改了，当其他线程要读取这个变量的时候，最终会去内存中读取，而不是从自己的工作空间中读取
	  - 当一个变量被声明为volatile时，在编译成会变指令的时候，会多出下面一行
	0x00bbacde: lock add1 $0x0,(%esp);  这条指令的前面有一个lock(锁)前缀，在寄存器执行一个加0的空操作
	处理器遇到lock指令时不会再锁住总线，而是会检查数据所在的内存区域，如果该数据是在处理器的内部缓存中，则会锁定此缓存区域，处理完后把缓存写回到主存中，并且会利用缓存一致性协议来保证其他处理器中的缓存数据的一致性

      - 缓存一致性协议：当某个CPU在写数据时，如果发现操作的变量是共享变量，则会通知其他CPU告知该变量的缓存行是无效的，因此其他CPU在读取该变量时，发现其无效会重新从主存中加载数据。
	线程中的处理器会一直在总线上嗅探其内部缓存中的内存地址在其他处理器的操作情况，一旦嗅探到某处处理器打算修改其内存地址中的值，而该内存地址刚好也在自己的内部缓存中，那么处理器就会强制让自己对该缓存地址的无效。所以当该处理器要访问该数据的时候，由于发现自己缓存的数据无效了，就会去主存中访问

    有序性
	  - 当我们把代码写好之后，虚拟机不一定会按照我们写的代码的顺序来执行
	    虚拟机在进行代码编译优化的时候，对于那些改变顺序之后不会对最终变量的值造成影响的代码，是有可能将他们进行重排序的
	    对于有些代码进行重排序之后，虽然对变量的值没有造成影响，但有可能会出现线程安全问题的
	    如果一个变量被声明volatile的话，那么这个变量不会被进行重排序，也就是说，虚拟机会保证这个变量之前的代码一定会比它先执行，而之后的代码一定会比它慢执行

    - 什么情况下volatile能够保证线程安全
	   - 运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值。
	   - 变量不需要与其他状态变量共同参与不变约束。


# ArrayList默认大小,以及空间扩展方法 (2-1)   
    - 1.不指定ArrayList的初始容量，在第一次add的时候会把容量初始化为10个，这个数值是确定的；
    - 2.ArrayList的扩容时机为add的时候容量不足，扩容的后的大小为原来的1.5倍，扩容需要拷贝以前数组的所有元素到新数组
    - 3.ArrayList是动态增长的数组，grow（）计算出新的扩容数组的size后实例化，并将原有数组内容Arrays.copyOf复制到新数组中去

# 泛型原理,常见集合类 (2-1)
    - 泛型：本质是类型的参数化，将所操作的数据类型指定为一个参数，参数类型可以用来类、方法、Map接口、集合中
    - 原理：泛型只存在于编译阶段,而不存在于运行阶段，编译的时候检查类型安全，并且所有的强制转换都是自动和隐式的，提高代码的重用率
    - 应用场景：类、方法、Map、集合
    - 通配符：? extends A 设置上限  ? super A  设置下限；泛型必须匹配才可以传递，否则无法传递
  
  ### 常见集合
      - List
      - Set
      - Queue
      - Map
# 内存划分: java 栈,堆,方法区等;(2-2)
 
    - java内存区域:
     - 虚拟机栈     （线程私有）   存储局部变量表、操作数栈、动态链接、方法出口等信息
	 - 本地方法栈   （线程私有）   存放着虚拟机使用到的Native方法服务
	 - 程序计数器 （线程私有）    记录的是正在执行的虚拟机字节码指令的地址
	 - 方法区    （线程共享）     内存中最大的一块，共享区域，类信息，常量信息，静态变量
	 - 堆      （线程共享）       内存中最大的一块，共享区域，保存对象实例以及数组，垃圾收集器进行垃圾收集的主要区域
	 - 本地内存：  不受JVM GC管理
	 

# HashMap原理, 冲突解决(2-2)
     HashMap基于Map接口实现，元素以键值对的方式存储，允许null键和null值，key不许重复，只允许一个null键，无序的不能保证放入元素的顺序，初始化大小16，负载因子0.75
	 hashmap与hashtable
	     1.线程安全：Hashtable是线程安全，而HashMap则非线程安全
		 2.针对null：HashMap可以使用null作为key，而Hashtable则不允许null作为key
		 3.继承结构：HashMap是对Map接口的实现，HashTable实现了Map接口和Dictionary抽象类
		 4.扩容大小：HashMap的初始容量为16，Hashtable初始容量为11，两者的填充因子默认都是0.75
		             - HashMap扩容时是当前容量翻倍即:capacity*2，Hashtable扩容时是容量翻倍+1即:capacity*2+1
		 5.两者计算hash的方法不同：Hashtable计算hash是直接使用key的hashcode对table数组的长度直接进行取模
		                           HashMap计算hash对key的hashcode进行了二次hash，以获得更好的散列值，然后对table数组长度取摸
								   
	HashMap是jdk1.7数组和链表的结构；1.8数组+链表+红黑树
	    put：添加键值对时，首先进行table是否初始化的判断，如果没有进行初始化（分配空间，Entry[]数组的长度16）。
	    然后进行key是否为null的判断，如果key==null ,放置在Entry[]的0号位置。
	    计算在Entry[]数组的存储位置，判断该位置上是否已有元素，如果已经有元素存在，则遍历该Entry[]数组位置上的单链表。
	    判断key是否存在，如果key已经存在，则用新的value值，替换点旧的value值，并将旧的value值返回。
	    如果key不存在于HashMap中，程序继续向下执行。将key-vlaue, 生成Entry实体，添加到HashMap中的Entry[]数组链表的尾部jdk1.8
	冲突解决：
	    - 线性（平方\随机）探测再散列法
		- 再散列法
		- 链地址法：将链表的头结点存在hash数组中，适用于经常插入和删除
		
# 强引用，弱引用，软引用，虚引用(2-3)
    - 把对象的引用分为4种级别，更加灵活的控制对象的生命周期
    - 强引用：[new] 垃圾回收器不会回收它，当内存不足的时候，会抛出OOM，程序终止
    - 软引用：如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存
        - 场景：实现内存敏感的高速缓存；1.例如浏览器的后退按钮，将浏览过的网页存储到存入软引用，
        取数据时就可从内存里取数据，提高运行效率，内存不足的是时候会自动清除软引用，避免造成内存溢出
        - 2.假设我们的应用会用到大量的默认图片，比如应用中有默认的头像，默认游戏图标等等，这些图片很多地方会用到。
        如果每次都去读取图片，由于读取文件需要硬件操作，速度较慢，会导致性能较低。所以我们考虑将图片缓存起来，需要的时候直接从内存中读取。但是，由于图片占用内存空间比较大，缓存很多图片需要很多的内存，就可能比较容易发生OutOfMemory异常。这时，我们可以考虑使用软引用技术来避免这个问题发生
    - 弱引用：垃圾回收器线程扫描内存中只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存
        - 场景：等同于软引用，生命周期更短，不影响垃圾回收
    - 虚引用：虚引用并不会决定对象的生命周期，任何时候都可以被垃圾回收。
        - 场景：主要用来跟踪对象被垃圾回收的活动。虚引用必须和引用队列（ReferenceQueue）联合使用
# ArrayBlockingQueue(2-2)
    - ArrayBlockingQueue：基于数组的阻塞队列，读写共享一个锁，吞吐量小，先进先出有界队列，不会OOM
    - LinkedBlockingQueue：基于链表的组赛队列，读写各有一个锁，吞吐量大，无界队列，内存浪费
    - add remove 异常
    - offer poll false null
    - put take 阻塞
    
#JVM垃圾回收算法,   CMS G1 等, 特性, fullGC,(2-3)
     java堆从GC的角度细分为：新生代1/3（Eden8/10，from1/10，to survivor1/10）和老年代2/3
	     - 新生代：用来存放新生的对象，由于频繁创建，所以新生代会频繁触发MinorGC，默认年龄15的对象会被移到老年代
		     - Eden：Java新对象的出生地。如果对象占用内存很大，直接分配到老年代，内存不够进行MinorGC，对新生代进行一次垃圾回收
	         - MinorGC采用复制算法：（复制-清空-互换）把eden和from中存活的对象保存到to中，同时把年龄+1，清空eden和from，将from和to互换
		 - 老年代：存放生命周期长的对象，不会频繁GC。内存不足MajorGC
		     - MajorGC：采用标记清除算法，扫描一次老年代，标记存活的对象，回收没有标记的对象。耗时长会产生内存碎片
			 - Full GC 是清理整个堆空间—包括年轻代和永久代
	     - 永久代：存放Class和Meta信息，GC不会在主程序运行期对永久区域进行清理
		 - JAVA8元数据：永久代已经被元空间取代，保存到java内存中，不受MaxPermSize控制，由系统实际可用空间控制；字符串池和类的常量信息放入java堆中
		 
		 - 如何确定是垃圾？
		     - 引用计数：通过引用计数来判断对象是否会回收，会产生循环计数问题
			 - 可达性分析：通过GC ROOT作为起点搜索，如果对象和gc root之间没有可达路径，则称该对象是不可达的；不可达对象经过两次标记仍是可回收对象，则面临回收
	     - 垃圾回收算法
		     - 标记清除：耗时长会产生内存碎片
			 - 复制算法：每次只使用一块内存，把存活的对象复制到另一块内存中去，把已经使用的内存清除掉
			 - 标记整理算法：标记后不是清理对象，将存活对象向内存一端移动，清除端边界外的对象
			 - 分代收集算法：新生代每次都有大量垃圾要回收，复制算法；老年代每次只有少量垃圾要回收，标记整理算法

         - CMS：多线程标记清除算法
		     - Concurrent mark sweep 是一种老年代垃圾收集器，主要目的是获取最短垃圾回收停顿时间，和标记整理算法不同，使用多线程的标记清除算法，最短的垃圾收集停顿时间，提供用户体验
			     - 初始标记：暂停所有工作线程：标记GC ROOT能直接关联的对象，速度很快
				 - 并发标记：不需要暂停工作线程：进行GC Root跟踪过程，和用户线程一起工作
				 - 重新标记：暂停所有工作线程：修正因程序继续运行导致标记变动的部分对象记录
				 - 并发清除：不需要暂停工作线程：清除GC Root不可达对象，和用户线程一起工作
		 - G1：避免全区域垃圾收集，把堆内存划分为大小固定的几个独立区域，跟踪这些区域的垃圾收集进度，同时在后台维护一个优先级列表，每次根据所允许的收集时间，优先回收垃圾最多的区域。
		        区域划分和优先级区域回收机制，确保G1垃圾收集器可以在有限的时间获得最高的垃圾回收效率
             1.基于标记整理算法，不产生内存碎片
			 2.可以非常精确的控制停顿时间，在不影响吞吐量的前提下，实现低停顿垃圾回收
# 多线程

 ## 线程同步, sleep wait (2-2)
     - 线程的状态 new runable running blocked dead
     - sleep 释放cpu时间片段，不释放锁
     - wait 让当前线程处于“等待(阻塞)状态”，“直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法
     - yeild 线程让步，主动让出CPU执行权，让其他线程也有相同的cpu优先级

 ## 可重入锁, synchronized 与lock 不同(2-2)
     不可重入锁：只判断这个锁有没有被锁上，只要被锁上申请锁的线程都会被要求等待。实现简单
     可重入锁：不仅判断锁有没有被锁上，还会判断锁是谁锁上的，当就是自己锁上的时候，那么他依旧可以再次访问临界资源，并把加锁次数加一。
         1.同一线程外层函数获得对象锁之后，内层递归函数仍然可以获取该对象锁的代码，而不会出现死锁  synchronized  ReentrantLock
	 作用及使用场景：
	     1.最大的作用就是可以避免死锁
		 2.当一个线程执行一个带锁的代码块或方法，代码块或方法里也获取同一个锁。为了避免死锁，可以用可重入锁。
	 相同点:两种方法在加锁和内存上提供相同的语义	
	 不同点：

     1.用法不一样，synchronized加在方法和特定的代码块上，lock需要显示的指定起始位置和结束位置；synchronized托管给JVM执行，lock通过代码执行
	 2.性能不一样，lock不仅拥有和synchronized相同的并发性，还增加了定时的锁等待、可中断的锁等待、公平与非公平锁。在资源竞争不激烈情况下，synchronized的性能要优于ReentrantLock，带在资源紧张很激烈的情况下，synchronized的性能会下降的很快，而ReentrantLock的性能基本保持不变
	 3.锁机制不一样。synchronized获得锁和释放锁的机制都在代码块结构中，当获得锁时，必须以相反的机制去释放，
	 并且自动解锁，不会因为异常导致没有被释放而导致死锁。而Lock需要开发人员手动去释放，并且写在finally代码块中，否则会可能引起死锁问题的发生。此外，Lock还提供的更强大的功能，可以通过tryLock的方式采用非阻塞的方式取获得锁。
	 
 # concurrentHashMap等线程优化集合;(2-2)
     jdk1.7中是采用Segment + HashEntry + ReentrantLock
	 jdk1.8中是采用Node + CAS + Synchronized
	 JDK1.7版本锁的粒度是基于Segment的，包含多个HashEntry，而JDK1.8锁的粒度就是HashEntry（首节点）
     JDK1.8使用红黑树来优化链表，基于长度很长的链表的遍历是一个很漫长的过程，而红黑树的遍历效率是很快的，代替一定阈值的链表，这样形成一个最佳拍档

	 用volatile修饰的Node
	     - 为了使得Node数组在扩容的时候对其他线程具有可见性而加的volatile
		 - get操作全程不需要加锁是因为Node的成员val是用volatile修饰的
     
     - 链表转换成红黑树的情况：1.数组长度大于等于64  2.单链表长度大于8
         - 红黑树是一颗弱平衡的二叉搜索树
         - 每个节点要么是黑色，要么是红色。
           根节点是黑色。
           每个叶子节点（NIL）是黑色。
           每个红色结点的两个子结点一定都是黑色。
           任意一结点到每个叶子结点的路径都包含数量相同的黑结点。
      - sizeCtl: -1表示初始化   -(1+n) n:表示活动的扩张线程  在实例化对象的时候指定了容量，则初始化sizeCtl=len*0.75 控制表初始化
      - 初始化数组table
          - 第一次put的时候，table还没被初始化，进入while
          - sizeCtl初始值为0，当小于0的时候表示在别的线程在初始化表或扩展表，让出yield
          - 否则cas修改sizeCtl的值
          - 指定了大小的时候就创建指定大小的Node数组，否则创建指定大小(16)的Node数组
          - 初始化后，sizeCtl长度为数组长度的3/4
      - putVal
          - 初始化：当添加一对键值对的时候，首先会去判断保存这些键值对的数组是不是初始化了，如果没有的话就初始化数组
          - 空：然后通过计算hash值来确定放在数组的哪个位置，如果这个位置为空则直接添加，如果不为空的话，则取出这个节点来
          - 扩容：如果取出来的节点的hash值是MOVED(-1)的话，则表示当前正在对这个数组进行扩容，复制到新的数组，则当前线程也去帮助复制
          - 加锁遍历：最后一种情况就是，如果这个节点，不为空，也不在扩容，则通过synchronized来加锁，进行添加操作，然后判断当前取出的节点位置存放的是链表还是树
          - 链表：如果是链表的话，则遍历整个链表，直到取出来的节点的key来个要放的key进行比较，如果key相等，并且key的hash值也相等的话，则说明是同一个key，则覆盖掉value，否则的话则添加到链表的末尾
          - 树：如果是树的话，则调用putTreeVal方法把这个元素添加到树中去
          - 扩容：最后在添加完成之后，会判断在该节点处共有多少个节点，不加当前节点大于等于8个的话
            则调用treeifyBin方法来尝试将处的链表转为树，或者扩容数组
          
       - treeifyBin
           - 当数组长度小于64的时候，扩张数组长度一倍，否则的话使用synchronized同步器，将该节点出的链表转为树
       - tryPresize:扩容表为可以容纳指定个数的大小（总是2的N次方），并没有加锁，允许多个线程进入，如果数组正在扩张，则当前线程也去帮助扩容
           - transfer
               - 1.将表拆分，让每个线程处理自己的区间，最小区间为16
               - 2.扩容的时候每处理一个节点，会在链表的头部设置一个fwd节点，这样其他线程就会跳过他
               - 3.根据节点的hash值判断Node在新表中的位置，0：新表的原来位置  n：新表的n+原来位置
               - 顺序大部分和原来是反的，分成两部分分别放到了原来的位置和新增加的长度的相同位置
       - get
           - 当key为null的时候回抛出NullPointerException的异常
           - get操作通过首先计算key的hash值来确定该元素放在数组的哪个位置
           - 然后遍历该位置的所有节点

# threadlocal(2-2)
    - 线程局部变量
        - 每个线程提供一个独立的变量副本解决了变量并发访问的冲突问题，ThreadLocal比直接使用synchronized同步机制解决线程安全问题更简单，更方便，且结果程序拥有更高的并发性。
        - ThreadLocal相当于维护了一个map，key就是当前的线程，value就是需要存储的对象
        - spring声明式事务的重要实现基础就是ThreadLocal
        - 内存泄漏
            - ThreadLocal引用被设置为null，且后面没有set，get,remove操作。
              ②线程一直运行，不停止。（线程池）
              ③触发了垃圾回收。（Minor GC或Full GC）

# JAVA线程池类型,特性 coresize maxsize (2-3)

# 线程数量如何判断,衡量方法(2-3)
    1、针对IO密集型的，阻塞耗时w一般都是计算耗时几倍c，假设阻塞耗时=计算耗时的情况下，Nthreads=Ncpu*(1+1)=2Ncpu,所以这种情况下，建议考虑2倍的CPU核心数做为线程数
    2、对于计算密集型的，阻塞耗时趋于0，即w/c趋于0，公式Nthreads = Ncpu+1。
# OOP设计模式

# 单例 模式 线程安全,延迟初始化(2-1)
    - 1. 懒汉模式（线程不安全）(懒加载)
    - 2. 线程安全的懒汉模式（线程安全）效率低
    - 3. 饿汉模式（线程安全）（无懒加载）
    - 4. 静态类内部加载（线程安全）静态内部类不会在单例加载时就加载，而是在调用getInstance()方法时才进行加载，达到了懒加载的效果，而这种方法又是线程安全的
    - 5. 枚举方法（线程安全）(可序列化)（懒加载）

```java
static enum SingletonEnum{
        //创建一个枚举对象，该对象天生为单例
        INSTANCE;
        private User user;
        //私有化枚举的构造函数
        private SingletonEnum(){
            user=new User();
        }
        public User getInstnce(){
            return user;
        }
    }
```
    - 6.双重校验锁法+volatile

# 工厂抽象工厂(2-2)
      - 简单工厂方法：一个工厂生产所有产品
      - 工厂方法：每个产品都有一个专属工厂，避免工厂类变成超级类（一个工厂生成所有对象）
      - 抽象工厂：同类工厂中抽象出工厂接口，具体工厂实现继承抽象工厂；只能横向扩展同类工厂
# 发布订阅模式(2-2)
      - 在被观察者Subject中注册添加观察者Observer
      - 发送通知时：被观察者调用观察者的update方法，更新通知
# 模板方法(2-1)
    - 定义一个抽象基类，创建一个final类型的算法框架和多个抽象方法
    - 子类继承抽象基类，实现抽象方法；使用的时候只要调用算法框架即可
# 桥接方法(2-2)
    - 将抽象部分与它的实现部分分离，使抽象部分和具体部分都可以独立地扩展
    - JDBC驱动器；JDBC为所有的关系型数据库提供一个通用的界面。一个应用系统动态地选择一个合适的驱动器，然后通过驱动器向数据库引擎发出指令。这个过程就是将抽象角色的行为委派给实现角色的过程。
# 装饰器模式(2-2)
    - 对已经存在的某些类进行装饰，扩展一些功能
    - 包装类和被包装类实现同一个接口，包装类在被包装类的基础上扩展功能，不影响被包装类
    - InputStream作为一个普通类，有多个具体装饰器比如BufferedInputStream、DataInputStream等
# Redis MemoryCache对比
    1.memcached所有的值均是简单的字符串，redis支持更丰富的数据类型
    2.Redis的速度比memcached快很多
    3.Redis可以持久化和事务
    
# Redis数据类型,以及底层实现, 单线程/多线程模型?(2-1)
    1.string：最基本的数据类型，字符串、整数或者浮点数，512M。[商品库存数，浏览数，点赞次数, 验证码。session，时效性][goodid value]
    2.list：有序双向链表，两端推入和弹出。2^32 - 1 [消息队列][lpush,rpop] [最新上架的商品][trim]
    3.set：无序不重复的字符串集合。2^32 - 1  [社交场景下的共同关注好友][交集，并集，差集]
    4.zset：已排序的字符串集合，分值大小决定排列顺序，根据分值范围(range)或者成员来获取元素。2^32 - 1 [排行榜][视频点赞数排行榜][微博热点排行榜]
    5.hash：包含键值对的无序散列表；可以让用户将多个键值对存储到一个Redis键里面。 2^32 - 1  [订单数据，商品数据，用户基本信息] hmset user:1 name james age 23 sex boy 
    - spring-data-redis
        redisTemplate.opsForValue();//操作字符串
        redisTemplate.opsForHash();//操作hash
        redisTemplate.opsForList();//操作list
        redisTemplate.opsForSet();//操作set
        redisTemplate.opsForZSet();//操作有序set
    - StringRedisTemplate与RedisTemplate
        - 关系：StringRedisTemplate继承RedisTemplate
        - 两者数据不互通
        - StringTemplate采用String序列化策略，RedisTemplate采用SDK序列化策略  
    
    redis优势：
    1.速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)
    2. 支持丰富数据类型，支持string，list，set，sorted set，hash
    3.支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行
    4. 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除
    
    单线程：
       - redis是基于内存的，CPU不是其瓶颈，瓶颈可能是内存或者网络带宽，单线程实现容易，避免锁的性能消耗，减少上下文切换时间
    IO多路复用：
       - 多个socket复用一个线程，多路IO复用计数可以让单线程高效的处理多个请求
    单点吞吐量
       - QPS：一台服务器每秒能够查询的次数：10万/s （单个接口一个处理）
       - TPS：每秒最大事务个数（一个事务包含多次查询）；8万 （一个请求对应多个处理） 
    哈希槽：redis cluster服务器数据分片：将数据存储到多台机器中去，可以提升查询性能 [客户端分片：一致性hash算法]
       - Redis集群没有使用一致性hash,而是引入了哈希槽的概念。
       - 当需要在 Redis 集群中放置一个 key-value 时，redis cluster有固定的16384个hash slot（哈希槽），对每个key计算CRC16值，然后对16384取模，可以获取key对应的hash slot
    场景：
       - session共享
       - 页面缓存
       - 计数器
    分布式锁：redis 在2.6.12版本 同时设置kv和过期时间  SET key value [EX seconds] [PX millisecounds] [NX|XX]
    
    redis+lua:1.性能  2.原子性
        - 1.所需要秒杀商品 及库存数据推到redis
        - 2.使用lua编写相应的脚本，放到redis去执行，返回0表示已秒过，返回2库存不足，返回1扣库存成功
        - lua ： 利用lua脚本淘汰用户，解决超卖问题
          - 1.用户是否已经秒过商品
          - 2.校验库存
          - 3.扣库存
          - 4.设置抢单成功
          - 5.返回结果

    - 在巨大的数据量的情况下，做类似于查找符合某种规则的Key的信息
        - 是keys命令，keys命令是以阻塞的方式执行的，keys是以遍历的方式实现的复杂度是 O(n），Redis库中的key越多，查找实现代价越大，产生的阻塞时间越长。keys key1111*
        - 是scan命令，以非阻塞的方式实现key值的查找，有一定的重复概率，客户端再做去重，时间较长。scan 0 match key1111* count 20

    - Redis做异步队列
      - list作为消息队列，rpush生产消息，lpop消费消息，当lpop没有消息的时候，适当sleep一会儿再重试，或者blpop阻塞
      - pub/sub主题订阅者模式，可以实现1:N的消息队列，在消费者下线的情况下，生产的消息会丢失
      - 延时队列：使用sortedset，拿时间戳作为score，消息内容作为key，调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理
# 主从同步方式(2-2)
    哨兵（Sentinel）和复制（Replication）
      - Sentinel可以监听集群中的服务器，当主服务器下线时，自动从从服务器中选举出新的从服务器。它提供了监控，提醒以及自动的故障转移的功能。高可用
      - Replication主从同步（复制）。扩展性
          - 一个主服务器可以有多个从服务器，从服务器也可以有自己的从服务器
          - 异步复制原理；从服务器向主服务器发送一个SYNC命令，主服务器将开始执行 BGSAVE，将所有的新操作命令保存到缓存区域，然后将保存的.rdb文件发给从服务器，从服务器接收到这个文件，将数据载入到内存中
    事务
      - 先以 MULTI 开始一个事务， 然后将多个命令入队到事务中， 最后由 EXEC 命令触发事务， 一并执行事务中的所有命令
      - 支持一次性按顺序执行多个命令的能力，可以理解为一个打包的批量执行脚本，但批量指令并非原子化的操作，中间某条指令的失败不会导致前面已做指令的回滚，也不会造成后续的指令不做
    LUA脚本
      - 在服务端一次性的执行更复杂的操作（包含一些逻辑判断）
    持久化
      - redis会把内存的中的数据写入到硬盘中，在redis重新启动的时候加载这些数据，从而最大限度的降低缓存丢失带来的影响。
          - RDB持久化方式能够将某个时间点的所有数据都存放到硬盘上，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本，数据量大，保存快照的时间会很长
          - AOF持久化方式以日志的形式记录每个写操作，AOF文件的体积不至于过大
          - AOF文件保存的数据集要比RDB文件保存的数据集要完整，数据恢复Redis会优先选择AOF恢复，RDB恢复数据集的速度要快很多
    复制
      - slaveof host port 让一个服务器成为另一个服务器的从服务器
      - 连接过程
          - 1.主服务器创建rdb快照文件，发给从服务器，并在发送期间在缓存区记录执行的写命令
          - 2.快照发送完毕后，开始向从服务器发送存储在缓存区的写命令
          - 3.从服务器丢弃所有数据，开始加载主服务器发来的rdb快照文件，之后接收主服务器发来的写命令
          - 4.主服务器每执行一次写命令就向从服务器发送一次写命令
       - 主从链
           - 随着负载不断的上升，主服务器无法很快的更新所有的从服务器，可以创建中间层服务器来分担主服务器的复制工作
    
    Java客户端：Redisson、Jedis、redisTemplate(spring-data)
        - opsForValue().set("k", "v")  //set字符串
        - opsForHash().putAll("hash", hash) //散列数据
        - opsForHash().entries("hash").forEach((k, v) -> {func} //遍历map
        - 
# Redis内存管理(2-2)
    对于过期数据的删除
      - 下次查询时，检查key超时时间，已超时则删除数据
      - 定时任务，默认每10秒一次，检查超时时间，超时删除

# 缓存击穿以及雪崩防止; 布隆过滤器方式(2-3)
    - 缓存穿透，是指查询一个数据库一定不存在的数据。每次查询都是空，每次又不进行缓存，容易压垮数据库。redis采用缓存空值的方法
        - 使用布隆过滤器对请求的key进行一层过滤，过滤掉系统认为不存在不合法的key
        - 使用双重验证锁解决高并发环境下的缓存穿透问题：1.从缓存中读取，校验object是否为null，如果不为空，返回缓存的值，否则  2.synchronized(this) ，再次从缓存中读取 3.如果为空的话，访问数据库，否则查询缓存
    - 缓存雪崩：在某一段时间内，缓存集中过期失效。不同分类的商品缓存不同的周期，热点商品缓存长，冷门商品缓存短
       - 对缓存的失效时间加上一个随机值，使失效时间分散一点，尽量避免集中失效
       - hystrix限流&降级组件，避免MySQL被打死
       - 如果真的发生雪崩，我们还可以用redis的RDB或AOF重启redis快速从磁盘加载缓存数据
    
    - 布隆过滤器：布隆过滤器是一个 bit 数组，特点是高效的插入和查询，缺点是返回的结果是概率性的
        - 使用多个hash函数生成多个hash值，对每一个hash值指向的bit位置为1。查询时，如果指定的位置不为1，肯定不存在；如果全部为1，可能存在
        - Redis 因其支持 setbit 和 getbit 操作，且纯内存性能高等特点，因此天然就可以作为布隆过滤器来使用。
          但是布隆过滤器的不当使用极易产生大 Value，增加 Redis 阻塞风险，因此生成环境中建议对体积庞大的布隆过滤器进行拆分。
          拆分的形式方法多种多样，但是本质是不要将 Hash(Key) 之后的请求分散在多个节点的多个小 bitmap 上，
          而是应该拆分成多个小 bitmap 之后，对一个 Key 的所有哈希函数都落在这一个小 bitmap 上

# 实现大文件的上传和断点续传
    - 1.计算全文件的md5，发送给服务器，服务器已存在，返回秒传成功，
    - 2.服务端不存在时，返回已经存在的切片序列，前端过滤已经上传的切片，批量上传没有的切片和每个切片的md5
    - 3.最后前端确定所有切片发完，发一个合并请求，做异步服务端合并，并校验合并完的md5，上传结束
# Spring

# AOP原理(2-1)
    - AOP的意思是面向切面编程，简单的说就是在方法执行前执行中和执行后可以自定义一些操作。
    - 一般都是基于代理模式实现的，Spring支持两种代理模式，jdk动态代理和cglib代理
    - JDK动态代理利用拦截器(拦截器必须实现InvocationHanlder)加上反射机制生成一个实现代理接口的匿名类
    - cglib代理利用ASM开源包，对代理对象类的class文件加载进来，通过修改其字节码生成子类来处理
    - AOP可以给程序带良好的扩展性和封装性，可以实现业务代码与非业务代码的隔离
    - 比如：可以在不改变目标代码的前提下，实现目标方法的增强，比如做方法执行时间监控，
    记录方法访问日志，再比如：数据库的connection.close()默认是把连接关闭掉，
    但是数据库连接池的场景中，为了不改变用户的使用习惯，一般调用close的时候是把连接重新放回到池中，
    这是因为从数据库连接池中拿到的连接实际上是原生连接的一个代理类，所以内部把close给重写了。
    实际上代理模式的优点实际上也是AOP的优点。
    
    IOC
     - IOC是控制反转的意思，可以用来降低程序代码之间的耦合度。
     - 把强耦合的代码放到统一的XML配置文件中，将程序对组件的主要控制权交给IOC，由IOC统一加载和管理
      DI：IOC通过DI进行依赖注入
        - 依赖注入包括set注入和构造器注入
      容器的两种形式
        - BeanFactory是一种低级容器，可以理解为就是一个HashMap，key是beanName，Value是Bean实例，是提供put，get两个功能    
        - ApplicationContext是高级容器，具备更多功能。
      初始化
         - IOC容器的初始化过程主要是在IOC容器中建立beanDefinition数据映射
         - 如果beanDefinition中有lazy-init属性，对Bean进行依赖注入
      实现过程：
         - 否则当用户向IOC容器索要bean的时候，调用BeanFactory的getBean方法，从 BeanDefinition 所属的 Map 里，拿出 Class 对象进行实例化，同时，如果有依赖关系，将递归调用 getBean 方法 —— 完成依赖注入
# spring mvc的controller默认是单例还是多例(2-1)
    - SpringMVC的controller默认使用了单例，在单例的bean中切记声明成员属性是线程不安全的，在并发时候会出现问题。
# SpringMVC请求处理流程(2-1)
    - 1.用户发起请求到前端控制器DispatcherServlet
    - 2.前端控制器请求处理映射器HandlerMapping查找Handler，处理映射器返回给前端控制器Hnadler
    - 3.前端控制器调用处理适配器HandlerAdapter去处理handler，handler执行完给适配器返回ModelAndView，适配器给前端控制器返回ModelAndView
    - 4.前端控制器请求视图解析器viewResolver，视图解析器返回给前端控制器view
    - 5.前端控制器将页面渲染，将model数据填充到reques中
    - 6.前端控制器向用户响应结果

# Spring 动态代理(2-2)
    - JDK动态代理利用拦截器(拦截器必须实现InvocationHanlder)加上反射机制生成一个实现代理接口的匿名类
    - cglib代理利用ASM开源包，对代理对象类的class文件加载进来，通过修改其字节码生成子类来处理

# 拦截器过滤器区别(2-2)
    - 1.拦截器是基于java反射的，过滤器是基于函数调用的
    - 2.拦截器依赖于web框架，过滤器依赖于servlet容器
    - 3.拦截器只能对action请求起作用，过滤器对几乎所有请求起作用
    - 4.拦截器可以访问action上下文，值栈里的对象，过滤器不可以
    - 5.在action的生命周期里，拦截器可以被多次调用，过滤器只能在容器初始化的时候调用一次
    - 6.拦截器可以获取IOC容器里面的各个bean，在拦截器里面注入servic，可以调用业务逻辑，过滤器不可以
# MYSQL 

# 内连接
    - MySQL 中内连接是在交叉连接的结果集上返回满足条件的记录
# 外连接
    - 外连接将表氛围基表和参考表，更加注重两张表之间的关系，按照连接顺序可以分为左外连接和右外连接
        - 左外连接：匹配左表中的每一行及右表中符合条件的行
# 如何创建联合索引
    - 1.create table ... KEY `sindex` (`aaa`, `bbb`, `ccc`)
    - 2.alter table add index `sindex` (`aaa`, `bbb`, `ccc`)
# 联合索引的存储结构
    - 联合索引(col1, col2,col3)也是一棵B+Tree，
        其非叶子节点存储的是第一个关键字的索引，
        而叶节点存储的则是三个关键字col1、col2、col3三个关键字的数据，
        且按照col1、col2、col3的顺序进行排序。
     - select的时候，第一列存在，索引能生效，3列都存在，索引全部生效，否则只能部分生效
    - 最左前缀原则：
      - 联合索引的B+Tree是按照第一个关键字进行索引排列的，查找的时候直接二分法查找第一列的索引，然后再第二列，再第三列

# where，having
   - where：从数据表中的字段直接进行筛选
   - having：从前面select后筛选的字段再进行筛选

# 聚簇索引与非聚簇索引(2-1)
    聚集索引
        - 数据表中数据的物理索引与键值的逻辑索引相同，inonodb中聚集索引就是主键索引，如果主键没有定义，该表的第一个唯一非空索引作为聚集索引，否则生成隐藏的6字节自增主键作为聚集索引
        - 一个表只能由一个聚集索引，可以有多个非聚集索引
        - 聚集索引整体是一个B+树，非叶子节点存放的是键值，叶子节点存放的是行数据，叶子之间通过双向链表连接
        - 非聚集索引，叶子节点存的是字段的键值，通过非聚集索引的键值找到对应的聚集索引的键值，再通过聚集索引的键值找到某行的数据
    聚集索引优点：
        1、以最快的速度缩小查询范围。
        2、以最快的速度进行字段排序。
    聚集索引使用场合：
        1、此列包含有限数目的不同值。
        2、查询的结果返回一个区间的值。
        3、查询的结果返回某值相同的大量结果集。



# 表格存储引擎innoDB Mysiam(2-1)
    - 事务：Myisam不支持事务，Myisam强调的是性能，执行速度比innodb快；innodb支持事务，默认开启自动提交
    - 主键：Myisam允许没有任何索引和主键的表存在，索引保存行的地址；innodb如果没有主键或者非空唯一索引，就会自动生成隐藏自增6字节主键作为聚集索引
    - 外键：Myisam不支持外键；innodb支持外键
    - 表锁：Myisam只执行表级别锁，select，update，delete，insert语句都会给表自动加锁；innodb支持行级锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的。大幅度提高了多用户并发操作性能
    - CRUD：Myisam执行大量SELECT效率高；innodb执行大量insert，update，delete效率高，全删使用truncate
    1) MyISAM管理非事务表。它提供高速存储和检索，以及全文搜索能力。如果应用中需要执行大量的SELECT查询，那么MyISAM是更好的选择。
    2) InnoDB用于事务处理应用程序，具有众多特性，包括ACID事务支持。如果应用中需要执行大量的INSERT或UPDATE操作，则应该使用InnoDB，这样可以提高多用户并发操作的性能。大尺寸数据倾向于innodb，因为事务日志和故障恢复
     
# 主从同步(2-2)
    - 主服务器操作数据库记录二进制日志，从服务器根据二进制日志自动执行更新
    - 二进制日志
        - 1.sql语句  2.每一行数据变化的信息  3.混合复制：默认用sql，出问题时用行数据复制
    - 主服务器只要发生变化，立马记录到binary log中
    - 从服务器启动一个thread连接到数据库中，请求Master变化的二进制日志
    - 从服务器获取到二进制日志，保存到自己的relay log中
    - 从服务器有一个SQL thread定期检查relay log是否变化，变化就自动更新
    
    为什么要用主从复制
       - 实现数据的异地备份
       - 实现负载均衡,读写分离
       - 提高数据库系统的可用性
   
# 读写分离(2-2)
    - 通过Mysql的主从复制结构，可以将读操作分散到从服务器中，并且对从服务器实现负载均衡
    - 问题：主从延迟
        - 从服务器通过主服务器的binary log文件进行同步有1秒的延迟，如果付款后，主库写入数据，但是从库查询不到数据
            - 1.数据库层面：分库，主库拆成读个主库，减小写并发量 2.从库开启多个线程并行复制
            - 2.软件层面：1.使用缓存保存状态，延缓查询时机  2.分配机制：选择不同数据源，关键业务由主库承担，
            
# 事务隔离级别(2-2)
    - Read uncommitted读未提交： 一个事务可以读取另一个未提交事务的数据 [脏读]
    - Read committed读已提交：一个事务要等另一个事务提交后才能读取数据，不能防止update，一个事务范围内两个相同的查询却返回了不同数据 [不可重复读]
    - Repeatable read可重复读【默认】：事务开启，不允许其他事务的UPDATE修改操作，两次读取的结果一致 由insert导致[幻读]：一次事务里，多次查询后，结果集的个数不一致
    - Serializable串行化：事务串行化顺序执行，可以避免脏读、不可重复读与幻读。但是这种事务隔离级别效率低下，比较耗数据库性能，一般不使用
# 幻读解决(2-2)
    - 幻读：一次事务里，多次查询后，结果集的个数不一致
    - 为什么要解决幻读：高并发场景中，要保证事务之间的隔离性和数据的一致性
    - mysql innodb引擎通过MVCC快照读和next-key(当前读)两种模式解决了幻读问题
    - 在快照读读情况下，mysql通过mvcc来避免幻读，简单的select操作
        - MVCC：多版本并发控制。InnoDB为每行记录添加了一个版本号（系统版本号），每当修改数据时，版本号加一；
        在读取事务开始时，系统会给事务一个当前版本号，事务会读取版本号<=当前版本号的数据，这时就算另一个事务插入一个数据，并立马提交，
        新插入这条数据的版本号会比读取事务的版本号高，因此读取事务读的数据还是不会变。
    - 在当前读读情况下，mysql通过next-key来避免幻读，next-key锁定一个范围的数据再事务提交之前不能变动
    
# B+树(2-3)
    - B树是m阶多路平衡查找树
      - 1.树中的每一个节点最多有m个子树
      - 2.除根节点和叶子节点外，其他节点最少有m/2个子节点
      - 3.所有的叶子节点都在同一层
      - 4.节点中的关键字顺序按照升序排列
    - B+树是B树的一种变体
        - 1.B+树非叶子节点不存在数据，只存储索引，每个非叶子节点存储的索引更多，树的层级更小
        - 2.叶子节点包含全部的关键信息，且叶子节点之间通过双向链表进行连接，查询更快
# ZK
    - ZooKeeper是一个开放源码的分布式协调服务，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作
    - 服务的注册与发现
    - 心跳检测，集群管理
# 分布式锁, 节点类型 (2-2)
    - 分布式锁/分布式队列 ： 根据zookeeper的一致性文件系统，在获取分布式锁的时候在locker节点下创建临时顺序节点，释放锁的时候删除该临时节点。
     - PERSISTENT-持久节点：除非手动删除，否则节点一直存在于Zookeeper上
     - EPHEMERAL-临时节点：临时节点的生命周期与客户端会话绑定，一旦客户端会话失效（客户端与zookeeper连接断开不一定会话失效），那么这个客户端创建的所有临时节点都会被移除。
     - PERSISTENT_SEQUENTIAL-持久顺序节点，基本特性同持久节点，只是增加了顺序属性，节点名后边会追加一个由父节点维护的自增整型数字。
     - EPHEMERAL_SEQUENTIAL-临时顺序节点，基本特性同临时节点，增加了顺序属性，节点名后边会追加一个由父节点维护的自增整型数字
# RPC&SOA
    - SOA:面向服务的架构，WebService/Dubbo作为服务
    - RPC:远程过程调用协议，通过网络调用远端服务，不知道具体实现，Thrift
# 服务治理,限流监控,降级,熔断等(2-3)
    - 服务治理：主要是解决微服务架构下微服务数量众多导致维护成本巨大的缺点，让维护人员从人工维护中解放，由服务自行维护
      微服务作为服务的提供方，主动向服务中心注册，服务的消费主要通过从服务中心查询需要的服务并进行调用
    - 服务发现监控Eureka：用于监控服务的注册与调用
     - Fiegn：简化rest接口调用操作，依赖于Ribbon
    - 服务降级：当服务器压力剧增的时候，对服务页面有策略的不处理或者简单处理，保证基本服务正常
        - 1.超时降级  2.失败次数降级  3.故障降级  4.限流降级  
    - 断路器（熔断）hystrix：1.断路器机制  2.Fallback  3.资源隔离
       1.断路器机制：当Hystrix Command 一定时间内请求后端服务失败数量超过一个阈值比例，该服务的断路器就会打开，返回一个由开发者设定的fallback
       2.fallback：由Hystrix保护的服务调用，也可以是固定的值，排队页面（将用户导流到排队页面等一会重试）、无货（直接告知用户没货了）、错误页（如活动太火爆了，稍后重试）
       3.资源隔离：不同的微服务调用使用不同的线程池来管理
    - 负载均衡Ribbon：1.最小请求数 2.轮询算法(默认)  3.随机算法
    - 服务网关zuul：提供一个统一的网关接口，实现服务的转发
    - 分布式配置：为微服务架构中的微服务提供集中化的外部配置支持
# 分布式事务(2-3)
    - 事务的属性：
        - 原子性：执行单元中的操作要么全部成功要么全部失败
        - 一致性：操作执行的前后都是完整的
        - 隔离性：事务与事务之间是完全隔离的，只有事务提交后其他事务才可以查询到最新的数据
        - 持久性：事务完成后对数据的改变会完整的存储起来
    - 分布式事务指多个系统通过网络共同完成一个事务，需要保证事务的ACID
        - 例如在下单场景中，库存和订单如果不在一个节点上，就涉及分布式事务
        - 两阶段提交协议（2PC）：由协调者和多个参与者组成，只要有一方参与者回复no，回滚事务。要求强一致性，性能低下
        - 事务补偿（TCC）：try满足条件检测 confirm执行资源操作  cancel有一方出现失败全部回滚。保证数据最终一致性，灵活性好，开发复杂
        - 基于消息队列的分布式事务：1.支付成功，本地事务更新订单状态，并向消息表写入减库存 
            2.定时任务扫描消息表，取出减库存消息并发向MQ  
            3.库存端收到消息先检测本地消息表是否有相同消息，存在说明已减库存，否则操作本地数据库减库存，并向本地消息表添加减库存消息，通过本地事务保证，
            4.向MQ发送完成减库存的消息
            5.收到消息后，删除本地消息表的减库存消息，提交事务
            - 本地消息的作用：即使宕机后恢复，确保消息能够被mq接收。做消息的持久化
        - 使用MQ事务消息：Rocketmq支持事务，如果确认消息失败会让发送端回滚。实现最终一致性，不需要依赖本地事务
        - 
    # cap、 base原则理解
      - cap：分布式系统在设计时只能在一致性(Consistency)、可用性(Availability)、分区容忍性(Partition Tolerance)中满足两种，无法兼顾三种
          - 一致性(Consistency)：多个节点的数据需要保证同一时刻数据的一致性
          - 可用性(Availability)：一个节点宕机不影响整个系统对外提供服务
          - 分区容忍性(Partition Tolerance)：解决由于网络分区导致的数据不完整和无法访问的问题
      - 无法同时兼顾CAP：保持分区容忍性不变的情况下，如果要提高可用性，就要增加多个结点，如果要保持一致性就要实现每个结点的数据一致，结点越多可用性越高，数据一致性越低
          - CA：关系型数据库
          - AP：NoSQL数据库
          - CP：跨行转账
          - 在分布式系统中，AP用得比较多，牺牲实时一致性，保持最终一致性，比如取消订单，退款稍后到帐，事务走完即可
      - base：BA指的是基本业务可用性，支持分区失败，S表示柔性状态，也就是允许短时间内不同步，E表示最终一致性，数据最终是一致的，但是实时是不一致的。
              原子性和持久性必须从根本上保障，为了可用性、性能和服务降级的需要，只有降低一致性和隔离性的要求。
# 什么是幂等性
    - 同一个操作无论请求多少次，结果都相同
# HTTP

# 状态码以及含义(2-1)
    - 1XX：通知
    - 2XX: 成功
    - 3XX 重定向
    - 4XX：客户端错误：不是认证信息有问题，就是表示格式或HTTP库本身有问题。客户端需要自行改正。
    - 5XX 服务端错误，服务器处于不能执行客户端请求的状态，客户端应稍后重试
    # 转发重定向
     1、转发所涉及的各个web组件可以共享同一个request对象，重定向不可以。
     2、重定向是两次请求，转发是一次请求。
     3、重定向之后，浏览器的网址会变，转发不变
     4、重定向的地址是任意的，转发的地址必须是同一应用中的地址
# 编程&&算法

# 生产者消费者模型 (2-1)
    # 阻塞队列
        - 异常：add remove element
        - 返回值：offer poll peek
        - 阻塞：put take
    - 线程池+阻塞队列实现
```java
//生产线程
public class ProductThread extends Thread {
    private int taskNum;
    private ArrayBlockingQueue queue;
    public ProductThread(int taskNum,ArrayBlockingQueue queue) {
        this.taskNum = taskNum;
        this.queue = queue;
    }
    public void run() {
        try {
            //模拟生产
            Thread.currentThread().sleep(5000);
            System.out.println("开始生产");
            queue.add(taskNum);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}
//消费者线程
public class ConsumerThread extends Thread {
    private ArrayBlockingQueue queue;
    public ConsumerThread(ArrayBlockingQueue queue) {
        this.queue = queue;
    }

    public void run() {
        System.out.println("准备消费");
            int taskNum;
            try {
                taskNum = (int) queue.take();
                System.out.println("消费了"+taskNum);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }   
    }
}
//主线程
public class ProductAndConsumer {

    public static void main(String[] args) {
        ArrayBlockingQueue<Integer> queue = new ArrayBlockingQueue<Integer>(20);
        //为多生产者和多消费者分别开创的线程池
        ThreadPoolExecutor productPool = 
                new ThreadPoolExecutor(10,20,60,TimeUnit.MILLISECONDS,new ArrayBlockingQueue(5),new ThreadPoolExecutor.CallerRunsPolicy());
        ThreadPoolExecutor consumerPool = 
                new ThreadPoolExecutor(10,20,60,TimeUnit.MILLISECONDS,new ArrayBlockingQueue(5),new ThreadPoolExecutor.CallerRunsPolicy());

        System.out.println("start");
        for(int i = 0;i<100;i++) {

            productPool.execute(new ProductThread(i,queue));
            consumerPool.execute(new ConsumerThread(queue));
        }
        productPool.shutdown();
        consumerPool.shutdown();
    }
}
```
# 三个有序数组合并(2-1)
    - 三指针
        - for三指针保存
        - for二指针保存
        - for一指针保存
    - 优先队列同时保存三个元素，入队出队
# 链表翻转 (2-1)

# 二叉树分层&&深度遍历(2-2)

# 一致性hash (2-2)
    - 原因：hash(object)%N +1-1的后所有的缓存都失效了
    - 一致性hash算法，在移除和添加结点的时候，尽可能小的改变已存在的key映射关系
    - 1.hash算法将value映射到一个0-32位的key值环形空间
    - 2.将对象和cache都映射到环形空间上
    - 3.把对象映射到缓存结点上，从对象的key值触发沿着顺时针方向，遇到的第一个cache，就将该对象存储在这个cache结点上
    - 4.如果移除一个cache结点，受影响的object将继续顺时针方向寻找下一个cache结点
    - 5.虚拟节点是为了使得缓存空间都得到合理的利用，解决服务结点的数据倾斜问题，hash环中虚拟节点均匀分布，多个虚拟结点对应一个实际结点
# 经典活动安排 (2-2)
 
# 最大连续子数组的和 (2-2)
      for (int i =0;i<arr.length;i++) {
                  curSum = (arr[i] > curSum + arr[i]) ? arr[i] : curSum + arr[i];//1---------
                  maxSum = (maxSum > curSum) ? maxSum : curSum;//2---------
              }
# int数组分为两个和最接近的子集 (2-3)
    - 划分等和子集，0，1背包   dp[target]
    - dp[j] = dp[j] || dp[j - nums[i]];
# Nginx负载均衡
    - 负载均衡，请求分发器，保证服务器集群的整体性能
        - 源地址哈希法
        - 轮询法
        - 随机法
        - 最小连接数法
        - 加权随机/轮询法
# 常见策略; (2-2)

# 架构题目

# 设计一个计算最大质数的服务; (2-3)
         for (int i=2;i*i < n;i++){
                     if (bool[i]){ //如果某位为素数
                         for(int j=i*i;j<n;j+=i){//素数的倍数都不是素数
                             bool[j] = false;
 
# 网络

# 三次握手、四次挥手过程
     第一次握手：建立连接时，客户端发送syn包（syn=j）到服务器，并进入SYN_SENT状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。
     第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态；
     第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。
     - 为了确定自己发送正常，接受正常，对方发送正常，接受正常

# 为什么断开连接需要四次挥手
    • 客户端-发送一个 FIN，用来关闭客户端到服务器的数据传送
    • 服务器-收到这个 FIN，它发回一 个 ACK，确认序号为收到的序号加1 。和 SYN 一样，一个 FIN 将占用一个序号
    • 服务器-关闭与客户端的连接，发送一个FIN给客户端
    • 客户端-发回 ACK 报文确认，并将确认序号设置为收到序号加1
    - 为了确定自己发送正常，接受正常，对方发送正常，接受正常
# TCP、UDP区别、应用场景
    - 1.连接：TCP面向连接（在客户端和服务器之间传输数据之前要先建立连接），UDP面向无连接（发送数据之前不需要先建立连接）
    - 2.可靠：TCP提供可靠的服务（通过TCP传输的数据。无差错，不丢失，不重复，且按序到达）；UDP提供面向事务的简单的不可靠的传输
    - 3.数据：TCP是流模式，UDP是数据报模式
    - 4.速度：UDP具有较好的实时性，工作效率比TCP高
    - 5.模式：TCP连接只能是点到点的，UDP支持一对一，一对多和多对多的交互通信
# 数据结构

# HashMap的实现原理
    HashMap基于Map接口实现，元素以键值对的方式存储，允许null键和null值，key不许重复，只允许一个null键，无序的不能保证放入元素的顺序，初始化大小16，负载因子0.75
    	 hashmap与hashtable
    	     1.线程安全：Hashtable是线程安全，而HashMap则非线程安全
    		 2.针对null：HashMap可以使用null作为key，而Hashtable则不允许null作为key
    		 3.继承结构：HashMap是对Map接口的实现，HashTable实现了Map接口和Dictionary抽象类
    		 4.扩容大小：HashMap的初始容量为16，Hashtable初始容量为11，两者的填充因子默认都是0.75
    		             - HashMap扩容时是当前容量翻倍即:capacity*2，Hashtable扩容时是容量翻倍+1即:capacity*2+1
    		 5.两者计算hash的方法不同：Hashtable计算hash是直接使用key的hashcode对table数组的长度直接进行取模
    		                           HashMap计算hash对key的hashcode进行了二次hash，以获得更好的散列值，然后对table数组长度取摸
    								   
    	HashMap是jdk1.7数组和链表的结构；1.8数组+链表+红黑树
    	    put：添加键值对时，首先进行table是否初始化的判断，如果没有进行初始化（分配空间，Entry[]数组的长度16）。
    	    然后进行key是否为null的判断，如果key==null ,放置在Entry[]的0号位置。
    	    计算在Entry[]数组的存储位置，判断该位置上是否已有元素，如果已经有元素存在，则遍历该Entry[]数组位置上的单链表。
    	    判断key是否存在，如果key已经存在，则用新的value值，替换点旧的value值，并将旧的value值返回。
    	    如果key不存在于HashMap中，程序继续向下执行。将key-vlaue, 生成Entry实体，添加到HashMap中的Entry[]数组链表的尾部jdk1.8
    	冲突解决：
    	    - 线性（平方\随机）探测再散列法
    		- 再散列法
    		- 链地址法：将链表的头结点存在hash数组中，适用于经常插入和删除
# HashMap数据结构？

# HashMap源码理解

# ConcurrentHashMap的实现原理

# 二叉树



# 算法

# 手写链表逆序代码
     while tmp = next.next
# 判断单项链表是否有环
     ListNode slow = head;
     ListNode fast = head.next;
     while (slow != fast) {
         if (fast == null || fast.next == null) {
             return false;
         }
         slow = slow.next;
         fast = fast.next.next;
     }
     return true;
# 一个数组里面所有数字都出现两次，只有一个（两次）数字出现一次，找出这个（两个）数字
    - hashset.contains(key) 已存在的话去除该数字
# 手写快排
    void qSort(int[] arr,int s,int e){
            int l = s, r = e;
            if(l < r){
                int temp = arr[l];
                while(l < r){
                    while(l < r && arr[r] >= temp) r--;  //从右边开始
                    if(l < r) arr[l] = arr[r];
                    while(l < r && arr[l] < temp) l++;
                    if(l < r) arr[r] = arr[l];
                }
                arr[l] = temp;
                qSort(arr,s,l);  //左半边递归
                qSort(arr,l + 1, e); //右半边递归
            }
        }

# 多线程

# volatile原理、作用
    - 可见性
    - 有序性：防止指令重排
# ReentrantLock 、synchronized和volatile比较
    1.用法不一样，synchronized加在方法和特定的代码块上，lock需要显示的指定起始位置和结束位置；synchronized托管给JVM执行，lock通过代码执行
    	 2.性能不一样，lock不仅拥有和synchronized相同的并发性，还增加了定时的锁等待、可中断的锁等待、公平与非公平锁。在资源竞争不激烈情况下，synchronized的性能要优于ReentrantLock，带在资源紧张很激烈的情况下，synchronized的性能会下降的很快，而ReentrantLock的性能基本保持不变
    	 3.锁机制不一样。synchronized获得锁和释放锁的机制都在代码块结构中，当获得锁时，必须以相反的机制去释放，
    	 并且自动解锁，不会因为异常导致没有被释放而导致死锁。而Lock需要开发人员手动去释放，并且写在finally代码块中，否则会可能引起死锁问题的发生。此外，Lock还提供的更强大的功能，可以通过tryLock的方式采用非阻塞的方式取获得锁。

# 对NIO、AIO的理解
    # 程序读取数据分两个步骤
        - 1.磁盘数据拷贝到系统内存
        - 2.系统内存拷贝到程序内存
        阻塞和非阻塞：第一步系统内存不停轮询数据有没有准备好，这就是非阻塞；如果一直等到有数据，这就是阻塞
        同步和异步：第二步应用内存拷贝数据时，线程或者进程会阻塞，不能去做其他事情，这就是同步；线程和进程可以做其他事情，这就是异步  
    bio是同步阻塞，一个连接启动一个线程去处理，包括准备数据和拷贝数据，期间不能做任何事情，很耗费系统资源
    nio是同步非阻塞，每个socket注册到多路复用器selector上，
        selector是一个单独的线程，会不断轮询注册到上面的socket，socket数据准备好了，就会开一个线程，拷贝数据到系统空间，可以处理大量并发请求
    aio是异步非阻塞，系统内存先把数据准备好，然后主动拷贝到程序内存中，拷贝好了，系统通知程序可以执行了，编程比较复杂，用的比较少
# 数据库

# 数据库的优化
    - 1.选取最合适的字段属性，数据库的表越小，执行的查询也就越快，因此为了获得更好的性能，将表中字段的宽度设置得尽量的小
    - 2.使用连接（JOIN）来代替子查询(Sub-Queries)：MySQL不需要在内存中创建临时表来完成这个逻辑上的需要两个步骤的查询工作
    - 3.使用联合(UNION)来代替手动创建的临时表。它可以把多个select的查询合并到一个查询中，查询会话结束时，临时表会自动删除，保证数据完整高效
    - 4.事务：使用事务来保证多用户访问同一个数据源时，利用锁定数据库提供一种安全的访问方式。BEGIN;COMMIT;
    - 5.锁定表：事务具有独占性，会影响数据库的性能，可以通过锁定表的方式获取更好的性能
    - 6.使用索引：可以让数据库服务器检索特定行的速度提升，ALTER TABLE或CREATE INDEX创建索引
    - 7.优化查询语句：避免使用!=或＜＞、IS NULL或IS NOT NULL、IN ，NOT IN等这样的操作符.会使得系统无法使用索引，用exists代替in
        - 能够用BETWEEN的就不要用IN
        
    MySQL表字段类型
        - INT，11位宽度
        - TINYINT ，0-255
        - SMALLINT ，65535
        - MEDIUMINT 
        - BIGINT ，20位
        - FLOAT，默认为10,2
        - DOUBLE，默认为16,4
        - DECIMAL
        
        - DATE 日期 YYYY-MM-DD
        - DATETIME 日期和时间 YYYY-MM-DD HH:MM:SS
        - TIMESTAMP 时间戳 YYYYMMDDHHMMSS
        
        - CHAR，固定长度的字符串1-255
        - VARCHAR，可变长度的字符串 
        - ENUM ，枚举
        - BLOB ，二进制大对象，存储图像，65535
# mysql索引理解
        - B树是m阶多路平衡查找树
              - 1.树中的每一个节点最多有m个子树
              - 2.除根节点和叶子节点外，其他节点最少有m/2个子节点
              - 3.所有的叶子节点都在同一层
              - 4.节点中的关键字顺序按照升序排列
            - B+树是B树的一种变体
                - 1.B+树非叶子节点不存在数据，只存储索引，每个非叶子节点存储的索引更多，树的层级更小
                - 2.叶子节点包含全部的关键信息，且叶子节点之间通过双向链表进行连接，查询更快
# Mysql常用存储引擎以及应用场景
            
            - 事务：Myisam不支持事务，Myisam强调的是性能，执行速度比innodb快；innodb支持事务，默认开启自动提交
                - 主键：Myisam允许没有任何索引和主键的表存在，索引保存行的地址；innodb如果没有主键或者非空唯一索引，就会自动生成隐藏自增6字节主键作为聚集索引
                - 外键：Myisam不支持外键；innodb支持外键
                - 表锁：Myisam只执行表级别锁，select，update，delete，insert语句都会给表自动加锁；innodb支持行级锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的。大幅度提高了多用户并发操作性能
                - CRUD：Myisam执行大量SELECT效率高；innodb执行大量insert，update，delete效率高，全删使用truncate
                1) MyISAM管理非事务表。它提供高速存储和检索，以及全文搜索能力。如果应用中需要执行大量的SELECT查询，那么MyISAM是更好的选择。
                2) InnoDB用于事务处理应用程序，具有众多特性，包括ACID事务支持。如果应用中需要执行大量的INSERT或UPDATE操作，则应该使用InnoDB，这样可以提高多用户并发操作的性能。大尺寸数据倾向于innodb，因为事务日志和故障恢复

# 聚簇索引和非聚簇索引的区别
        聚集索引
            - 数据表中数据的物理索引与键值的逻辑索引相同，inonodb中聚集索引就是主键索引，如果主键没有定义，该表的第一个唯一非空索引作为聚集索引，否则生成隐藏的6字节自增主键作为聚集索引
            - 一个表只能由一个聚集索引，可以有多个非聚集索引
            - 聚集索引整体是一个B+树，非叶子节点存放的是键值，叶子节点存放的是行数据，叶子之间通过双向链表连接
            - 非聚集索引，叶子节点存的是字段的键值，通过非聚集索引的键值找到对应的聚集索引的键值，再通过聚集索引的键值找到某行的数据
        聚集索引优点：
            1、以最快的速度缩小查询范围。
            2、以最快的速度进行字段排序。
        聚集索引使用场合：
            1、此列包含有限数目的不同值。
            2、查询的结果返回一个区间的值。
            3、查询的结果返回某值相同的大量结果集。
# Mysql索引数据结构及优化
       Mysql的两种主要的存储引擎都依赖的数据结构为B+tree
       目前比较主流的存储引擎貌似是MyISAM和InnoDB两种
           - MyISAM使用B+tree存储引擎结构，叶节点的data域存放的是数据记录的地址
           - MyISAM采用的是索引文件和数据文件分离存储，索引文件中存储的是数据文件中相应数据的地址，只对索引采取B+tree数据结构
           - 主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复
         
           - InnoDB的数据文件本身就是索引文件，数据文件就按照B+tree的结构存储，这棵树的key即是InnoDB中的主键，
               这棵树的叶结点对应的data域存储的是完整的数据记录，这种索引叫做聚集索引，MyISAM则不是非要主键，MyISAM的索引叫做非聚集索引
           - 在InnoDB中的辅助索引和MyISAM中的辅助索引也不一样，InnoDB的辅助索引也采用的B+tree结构存储，
              但是辅助索引树的叶结点的data域则存储的是相应的主键值，而不是像MyISAM存储地址
           - 辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录，所以InnoDB的主键最好使用单调有序的字段
           
       优化：
           - where后面的索引列不能包含表达式和函数
           - 将选择性最好的列放在索引的最前l列
           - 减少创建冗余索引，当前条查询语句相关的索引数量越多，效率越低
# 索引匹配规则
    - explain：查看sql语句的执行计划   index 全表查询  ref 找符合条件的索引
    - 索引的最左匹配特性：当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，b+树会优先比较name来确定下一步的所搜方向
    - 复合索引：复合索引中，mysql优化器会纠正sql以什么样的顺序执行效率会更高，mysql查询优化器最终会以这种顺序进行查询执行

# 基础组件

# zookeeper选举过程
    目前有5台服务器，每台服务器均没有数据，它们的编号分别是1,2,3,4,5,按编号依次启动，它们的选择举过程如下：
    
    服务器1启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反馈信息，服务器1的状态一直属于Looking(选举状态)。
    服务器2启动，给自己投票，同时与之前启动的服务器1交换结果，由于服务器2的编号大所以服务器2胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是LOOKING。
    服务器3启动，给自己投票，同时与之前启动的服务器1,2交换信息，由于服务器3的编号最大所以服务器3胜出，此时投票数正好大于半数，所以服务器3成为领导者，服务器1,2成为小弟FOLLOWING。
    服务器4启动，给自己投票，同时与之前启动的服务器1,2,3交换信息，尽管服务器4的编号大，但之前服务器3已经胜出，所以服务器4只能成为小弟FOLLOWING。
    服务器5启动，后面的逻辑同服务器4成为小弟FOLLOWING。
    
# kafka原理
    - 分布式消息发布和订阅系统，它的特点是高性能、高吞吐量
    - 有多个生产者和消费者，每一个生产者有多个topic，每一个消费者只属于一个消费者组
    - 在Kafka中的每一条消息都有一个topic，每个Topics类似于一张queue，queue中有多个partition，每个partition对应了操作系统上的一个文件夹，每个partition由多个segment文件组成，
    - partition里的数据是有序的，partition间的数据是无序的，将partition设置为1可以保证消息的有序性
    - 每个消息都有一个64字节的offset，表示消息在partition中的位置
    - Broker是kafka结点，一个kafka结点就是一个broker，多个broker可以组成kafka集群，直接使用磁盘进行存储，线性读写，速度快
    - 消费模式：Kafka采取拉取模型(poll)，由自己控制消费速度，以及消费的进度，消费者可以按照任意的偏移量进行消费
    - 日志存储：segment文件由两部分组成，分别为.index稀疏索引文件和.log日志文件，加快查询速度
        - segment的命名规则：第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息offse值
        - 查找算法：1.根据offset的值，先使用二分法查找index文件，找到索引文件中符合范围的索引partition 2.再到对应的log文件中，从partition开始查找offset对应的消息
# kafka如何保证大吞吐量、高性能
    - 可靠性：同一个分区的多个副本会被均匀分配到集群中的不同broker上，当leader副本所在的broker出现故障后，可以重新选举新的leader副本继续对外提供服务。通过这样的副本机制来提高kafka集群的可用性
    - 高性能：
        - 1.Kafka是将消息记录持久化到本地磁盘中的，基于本地磁盘的顺序读写性能甚至比内存随机读写性能高，kafka通过磁盘的顺序读写来提升性能
        - 2.Kafka利用了操作系统本身的Page Cache，，而不是JVM空间内存，避免Object内存消耗和GC
        - 3.使用了零拷贝机制，允许操作系统直接将数据从Page Cache直接发送到网络，避免了数据在内核空间和用户空间之间的拷贝  
        - 4.通过分区分段+索引的机制，提升了数据的读取效率和并行操作效率
        - 5.kafka通过批量压缩和批量读写，降低延迟和带宽消耗，提升性能
    - 吞吐量：Kafka的message是不断追加到本地磁盘文件末尾的，而不是随机的写入，这使得Kafka写入吞吐量得到了显著提升 
    
# 零拷贝：一种新的数据传输方式
           - 传统数据传输：数据从磁盘读取到内核，从内核拷贝到用户进程，又拷贝回内核，最后通过套接字发送，实际上如果不对文件进行修改的话，中间步骤是不需要做的
           -  零拷贝：内核将磁盘数据直接拷贝到套接字而不再经过应用，能较少复制拷贝次数，还能较少上下文切换，缓存污染